<p style="font-size:19px; text-align:left; margin-top:    25px;"><i>German Association of Actuaries (DAV) — Working Group "Explainable Artificial Intelligence"</i></p>
<p style="font-size:25px; text-align:left; margin-bottom: 15px"><b>Model-Agnostic Explainability Methods for Regression Problems:<br>
A Case Study on Medical Costs Data</b></p>
<p style="font-size:19px; text-align:left; margin-bottom: 15px; margin-bottom: 25px">Dr. Simon Hatzesberger (<a href="mailto:simon.hatzesberger@gmail.com">simon.hatzesberger@gmail.com</a>)


<i>
In this Jupyter Notebook, we offer a practical walkthrough for actuaries and data scientists on applying model-agnostic explainability methods to regression tasks, with a medical costs dataset serving as our case study.
</i>
<br>

<i>
It illuminates both global methods—such as surrogate models, PDPs, ALE plots, and permutation feature importances—for macro-level understanding of model behavior, and local methods—like SHAP, LIME, and ICE plots—for micro-level insights on individual predictions.
</i>
<br>

<i>
The notebook provides practical code examples that readers can easily adopt, thereby providing a user-friendly introduction to using XAI methods to enhance transparency and reliability of their predictive models.
</i>

